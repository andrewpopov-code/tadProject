{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-30T06:09:59.646490Z",
     "start_time": "2024-03-30T06:09:53.848595Z"
    }
   },
   "outputs": [],
   "source": [
    "from nn import TopologyMixin, TopologyTrainingObserver\n",
    "\n",
    "# PyTorch model and training necessities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Image datasets and image manipulation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Image display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gather datasets and prepare them for consumption\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Store separate training and validations splits in ./data\n",
    "training_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set,\n",
    "                                              batch_size=4,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2)\n",
    "\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                batch_size=4,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=2)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# Extract a batch of 4 images\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T06:10:03.675442Z",
     "start_time": "2024-03-30T06:09:59.659549Z"
    }
   },
   "id": "1b3170ae70a9e3a1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Default log_dir argument is \"runs\" - but it's good to be specific\n",
    "# torch.utils.tensorboard.SummaryWriter is imported above\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_2')\n",
    "\n",
    "# Write image data to TensorBoard log dir\n",
    "writer.add_image('Four Fashion-MNIST Images', img_grid)\n",
    "writer.flush()\n",
    "\n",
    "# To view, start TensorBoard on the command line with:\n",
    "#   tensorboard --logdir=runs\n",
    "# ...and open a browser tab to http://localhost:6006/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T06:10:03.679291Z",
     "start_time": "2024-03-30T06:10:03.667385Z"
    }
   },
   "id": "8580e29bad3914e2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Net(nn.Module, TopologyMixin):\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        TopologyMixin.__init__(self, writer=writer)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x, topology: bool = False):\n",
    "        if topology:\n",
    "            self.Filtration(x.transpose(1, 2).transpose(2, 3), label='Input', distances=False, batches=True)\n",
    "            self.Dimension(x.transpose(1, 2).transpose(2, 3), label='Dimension Analysis', distances=False, batches=True)\n",
    "            self.DeltaHyperbolicity(x.transpose(1, 2).transpose(2, 3), label='Hyperbolicity Analysis', distances=False, batches=True)\n",
    "            \n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            self.Filtration(x.transpose(1, 2).transpose(2, 3), label='Hidden', distances=False, batches=True)\n",
    "            self.Dimension(x.transpose(1, 2).transpose(2, 3), label='Dimension Analysis', distances=False, batches=True)\n",
    "            self.DeltaHyperbolicity(x.transpose(1, 2).transpose(2, 3), label='Hyperbolicity Analysis', distances=False, batches=True)\n",
    "            \n",
    "            x = x.view(-1, 16 * 4 * 4)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T06:10:03.727318Z",
     "start_time": "2024-03-30T06:10:03.695808Z"
    }
   },
   "id": "8244d6c68915ddd1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "observer = TopologyTrainingObserver(net, reset=False, log_every_train=1000, log_every_val=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T06:10:03.729915Z",
     "start_time": "2024-03-30T06:10:03.706205Z"
    }
   },
   "id": "bb701b31df137aa"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Net(\n  (Filtration): Persistence()\n  (Dimension): IntrinsicDimension()\n  (Entropy): Entropy()\n  (DeltaHyperbolicity): DeltaHyperbolicity()\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=256, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.Entropy.parent()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T06:02:00.006074Z",
     "start_time": "2024-03-30T06:01:59.994616Z"
    }
   },
   "id": "68baff361ae001bf"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from topology import DeltaHyperbolicity, IntrinsicDimension\n",
    "from nn import TopologyObserver\n",
    "\n",
    "Dimension = IntrinsicDimension()\n",
    "DH = DeltaHyperbolicity()\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x, topology: bool = False):\n",
    "        if topology:\n",
    "            Dimension(x.transpose(1, 2).transpose(2, 3), label='Dimension Analysis', distances=False, batches=True)\n",
    "            DH(x.transpose(1, 2).transpose(2, 3), label='Hyperbolicity Analysis', distances=False, batches=True)\n",
    "            \n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            Dimension(x.transpose(1, 2).transpose(2, 3), label='Dimension Analysis', distances=False, batches=True)\n",
    "            DH(x.transpose(1, 2).transpose(2, 3), label='Hyperbolicity Analysis', distances=False, batches=True)\n",
    "            \n",
    "            x = x.view(-1, 16 * 4 * 4)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:40:15.429989Z",
     "start_time": "2024-03-28T17:40:15.403940Z"
    }
   },
   "id": "77811661cfb83108"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "observer = TopologyObserver(net, writer, [Dimension, DH])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:40:15.431647Z",
     "start_time": "2024-03-28T17:40:15.416545Z"
    }
   },
   "id": "9d310d0e71034b3e"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "{5827103904: IntrinsicDimension(), 5808434528: DeltaHyperbolicity()}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observer.topology_modules"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:34:58.106278Z",
     "start_time": "2024-03-28T17:34:58.083814Z"
    }
   },
   "id": "3327b33f5cbdd8c8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([(7,\n              <function topology.module.TopologyModule.tag_hook(self: 'TopologyModule', args: tuple, kwargs: dict, result)>),\n             (6,\n              <function topology.module.TopologyModule.writer_hook(self: 'TopologyModule', args: tuple, kwargs: dict, result)>),\n             (5,\n              <function topology.dimension.IntrinsicDimension.log(self: 'IntrinsicDimension', args: tuple, kwargs: dict, result)>),\n             (1,\n              <function topology.module.TopologyModule.increment(self: 'TopologyModule', args: tuple, result)>)])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dimension._forward_hooks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:40:18.127297Z",
     "start_time": "2024-03-28T17:40:18.116230Z"
    }
   },
   "id": "43048c59a307191"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Log Validation Results\n",
    "net.eval()\n",
    "vdata = next(iter(validation_loader))\n",
    "vinputs, vlabels = vdata\n",
    "voutputs = net(vinputs, topology=True)\n",
    "vloss = criterion(voutputs, vlabels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:40:27.344537Z",
     "start_time": "2024-03-28T17:40:23.634089Z"
    }
   },
   "id": "8d742bcb86ed5712"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1.8609, 2.0353, 2.1721, 1.8744]), tensor([0., 0., 0., 0.]))"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from topology import IntrinsicDimension\n",
    "Dimension = IntrinsicDimension(writer=writer)\n",
    "Dimension.add_log_hook()\n",
    "x = vinputs\n",
    "Dimension(x.transpose(1, 2).transpose(2, 3), label='Dimension Analysis', distances=False, batches=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:28:37.903597Z",
     "start_time": "2024-03-28T17:28:37.868388Z"
    }
   },
   "id": "86f3463fcf5c4e95"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "Dimension.parent()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:34:16.273722Z",
     "start_time": "2024-03-28T17:34:16.261513Z"
    }
   },
   "id": "2aa8563e527cb63a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'ID Profile 5808612736: Dimension Analysis'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(Dimension.get_tags()) + ': ' + 'Dimension Analysis'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:25:18.215633Z",
     "start_time": "2024-03-28T17:25:18.201404Z"
    }
   },
   "id": "a35fec81ed8eb03"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1.8609, 2.0353, 2.1721, 1.8744]), tensor([0., 0., 0., 0.]))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = vinputs\n",
    "res = net.Dimension(x.transpose(1, 2).transpose(2, 3), label='Dimension Analysis', distances=False, batches=True)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T16:55:41.623129Z",
     "start_time": "2024-03-28T16:55:41.594204Z"
    }
   },
   "id": "31c6096c4af159ce"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([6.7247, 5.7119, 2.5959, 3.5795]), tensor([0., 0., 0., 0.]))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = net.pool(F.relu(net.conv1(x)))\n",
    "x = net.pool(F.relu(net.conv2(x)))\n",
    "net.Dimension(x.transpose(1, 2).transpose(2, 3), label='Dimension Analysis', distances=False, batches=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T16:55:49.665205Z",
     "start_time": "2024-03-28T16:55:49.623263Z"
    }
   },
   "id": "2696c8550699cd5d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 16, 4, 4])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = net.pool(F.relu(net.conv1(x)))\n",
    "x = net.pool(F.relu(net.conv2(x)))\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T14:40:47.743114Z",
     "start_time": "2024-03-28T14:40:47.706172Z"
    }
   },
   "id": "33d0c62f7ccc0bc"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 4, 4, 4])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(0, 1).transpose(1, 2).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T14:41:16.590151Z",
     "start_time": "2024-03-28T14:41:16.579534Z"
    }
   },
   "id": "53b0a6de87d746d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e407ccc5eef50697"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0118],\n         [0.0039],\n         [0.0000],\n         [0.0000],\n         [0.0275],\n         [0.0000],\n         [0.1451],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0039],\n         [0.0078],\n         [0.0000],\n         [0.1059],\n         [0.3294],\n         [0.0431],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.4667],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0039],\n         [0.0000],\n         [0.0000],\n         [0.3451],\n         [0.5608],\n         [0.4314],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0863],\n         [0.3647],\n         [0.4157],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0157],\n         [0.0000],\n         [0.2078],\n         [0.5059],\n         [0.4706],\n         [0.5765],\n         [0.6863],\n         [0.6157],\n         [0.6510],\n         [0.5294],\n         [0.6039],\n         [0.6588],\n         [0.5490],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0078],\n         [0.0000],\n         [0.0431],\n         [0.5373],\n         [0.5098],\n         [0.5020],\n         [0.6275],\n         [0.6902],\n         [0.6235],\n         [0.6549],\n         [0.6980],\n         [0.5843],\n         [0.5922],\n         [0.5647],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0039],\n         [0.0000],\n         [0.0078],\n         [0.0039],\n         [0.0000],\n         [0.0118],\n         [0.0000],\n         [0.0000],\n         [0.4510],\n         [0.4471],\n         [0.4157],\n         [0.5373],\n         [0.6588],\n         [0.6000],\n         [0.6118],\n         [0.6471],\n         [0.6549],\n         [0.5608],\n         [0.6157],\n         [0.6196],\n         [0.0431],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0039],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0118],\n         [0.0000],\n         [0.0000],\n         [0.3490],\n         [0.5451],\n         [0.3529],\n         [0.3686],\n         [0.6000],\n         [0.5843],\n         [0.5137],\n         [0.5922],\n         [0.6627],\n         [0.6745],\n         [0.5608],\n         [0.6235],\n         [0.6627],\n         [0.1882],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0078],\n         [0.0157],\n         [0.0039],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.3843],\n         [0.5333],\n         [0.4314],\n         [0.4275],\n         [0.4314],\n         [0.6353],\n         [0.5294],\n         [0.5647],\n         [0.5843],\n         [0.6235],\n         [0.6549],\n         [0.5647],\n         [0.6196],\n         [0.6627],\n         [0.4667],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0078],\n         [0.0078],\n         [0.0039],\n         [0.0078],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.1020],\n         [0.4235],\n         [0.4588],\n         [0.3882],\n         [0.4353],\n         [0.4588],\n         [0.5333],\n         [0.6118],\n         [0.5255],\n         [0.6039],\n         [0.6039],\n         [0.6118],\n         [0.6275],\n         [0.5529],\n         [0.5765],\n         [0.6118],\n         [0.6980],\n         [0.0000]],\n\n        [[0.0118],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0824],\n         [0.2078],\n         [0.3608],\n         [0.4588],\n         [0.4353],\n         [0.4039],\n         [0.4510],\n         [0.5059],\n         [0.5255],\n         [0.5608],\n         [0.6039],\n         [0.6471],\n         [0.6667],\n         [0.6039],\n         [0.5922],\n         [0.6039],\n         [0.5608],\n         [0.5412],\n         [0.5882],\n         [0.6471],\n         [0.1686]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0902],\n         [0.2118],\n         [0.2549],\n         [0.2980],\n         [0.3333],\n         [0.4627],\n         [0.5020],\n         [0.4824],\n         [0.4353],\n         [0.4431],\n         [0.4627],\n         [0.4980],\n         [0.4902],\n         [0.5451],\n         [0.5216],\n         [0.5333],\n         [0.6275],\n         [0.5490],\n         [0.6078],\n         [0.6314],\n         [0.5647],\n         [0.6078],\n         [0.6745],\n         [0.6314],\n         [0.7412],\n         [0.2431]],\n\n        [[0.0000],\n         [0.2667],\n         [0.3686],\n         [0.3529],\n         [0.4353],\n         [0.4471],\n         [0.4353],\n         [0.4471],\n         [0.4510],\n         [0.4980],\n         [0.5294],\n         [0.5333],\n         [0.5608],\n         [0.4941],\n         [0.4980],\n         [0.5922],\n         [0.6039],\n         [0.5608],\n         [0.5804],\n         [0.4902],\n         [0.6353],\n         [0.6353],\n         [0.5647],\n         [0.5412],\n         [0.6000],\n         [0.6353],\n         [0.7686],\n         [0.2275]],\n\n        [[0.2745],\n         [0.6627],\n         [0.5059],\n         [0.4078],\n         [0.3843],\n         [0.3922],\n         [0.3686],\n         [0.3804],\n         [0.3843],\n         [0.4000],\n         [0.4235],\n         [0.4157],\n         [0.4667],\n         [0.4706],\n         [0.5059],\n         [0.5843],\n         [0.6118],\n         [0.6549],\n         [0.7451],\n         [0.7451],\n         [0.7686],\n         [0.7765],\n         [0.7765],\n         [0.7333],\n         [0.7725],\n         [0.7412],\n         [0.7216],\n         [0.1412]],\n\n        [[0.0627],\n         [0.4941],\n         [0.6706],\n         [0.7373],\n         [0.7373],\n         [0.7216],\n         [0.6706],\n         [0.6000],\n         [0.5294],\n         [0.4706],\n         [0.4941],\n         [0.4980],\n         [0.5725],\n         [0.7255],\n         [0.7647],\n         [0.8196],\n         [0.8157],\n         [1.0000],\n         [0.8196],\n         [0.6941],\n         [0.9608],\n         [0.9882],\n         [0.9843],\n         [0.9843],\n         [0.9686],\n         [0.8627],\n         [0.8078],\n         [0.1922]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0471],\n         [0.2627],\n         [0.4157],\n         [0.6431],\n         [0.7255],\n         [0.7804],\n         [0.8235],\n         [0.8275],\n         [0.8235],\n         [0.8157],\n         [0.7451],\n         [0.5882],\n         [0.3216],\n         [0.0314],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.6980],\n         [0.8157],\n         [0.7373],\n         [0.6863],\n         [0.6353],\n         [0.6196],\n         [0.5922],\n         [0.0431]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]],\n\n        [[0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000],\n         [0.0000]]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(vinputs[0] / 2 + 0.5).transpose(0, 1).transpose(1, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T11:16:40.277243Z",
     "start_time": "2024-03-26T11:16:40.249287Z"
    }
   },
   "id": "7997b6edfffcbcf5"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "0\n",
      "Batch 1 Observer step: 0\n",
      "Validation Batch 1 Observer step: 1\n",
      "Validation Batch 1001 Observer step: 1001\n",
      "Validation Batch 2001 Observer step: 2001\n",
      "Batch 1001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 3501\n",
      "Validation Batch 1001 Observer step: 4501\n",
      "Validation Batch 2001 Observer step: 5501\n",
      "Batch 2001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 7001\n",
      "Validation Batch 1001 Observer step: 8001\n",
      "Validation Batch 2001 Observer step: 9001\n",
      "Batch 3001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 10501\n",
      "Validation Batch 1001 Observer step: 11501\n",
      "Validation Batch 2001 Observer step: 12501\n",
      "Batch 4001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 14001\n",
      "Validation Batch 1001 Observer step: 15001\n",
      "Validation Batch 2001 Observer step: 16001\n",
      "Batch 5001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 17501\n",
      "Validation Batch 1001 Observer step: 18501\n",
      "Validation Batch 2001 Observer step: 19501\n",
      "Batch 6001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 21001\n",
      "Validation Batch 1001 Observer step: 22001\n",
      "Validation Batch 2001 Observer step: 23001\n",
      "Batch 7001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 24501\n",
      "Validation Batch 1001 Observer step: 25501\n",
      "Validation Batch 2001 Observer step: 26501\n",
      "Batch 8001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 28001\n",
      "Validation Batch 1001 Observer step: 29001\n",
      "Validation Batch 2001 Observer step: 30001\n",
      "Batch 9001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 31501\n",
      "Validation Batch 1001 Observer step: 32501\n",
      "Validation Batch 2001 Observer step: 33501\n",
      "Batch 10001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 35001\n",
      "Validation Batch 1001 Observer step: 36001\n",
      "Validation Batch 2001 Observer step: 37001\n",
      "Batch 11001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 38501\n",
      "Validation Batch 1001 Observer step: 39501\n",
      "Validation Batch 2001 Observer step: 40501\n",
      "Batch 12001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 42001\n",
      "Validation Batch 1001 Observer step: 43001\n",
      "Validation Batch 2001 Observer step: 44001\n",
      "Batch 13001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 45501\n",
      "Validation Batch 1001 Observer step: 46501\n",
      "Validation Batch 2001 Observer step: 47501\n",
      "Batch 14001 Observer step: 0\n",
      "Validation Batch 1 Observer step: 49001\n",
      "Validation Batch 1001 Observer step: 50001\n",
      "Validation Batch 2001 Observer step: 51001\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_loader))\n",
    "observer.flush()\n",
    "net.train(True)\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    print(observer.step)\n",
    "\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        # basic training loop\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs, topology=i % 1000 == 0)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 0:    # Every 1000 mini-batches...\n",
    "            print('Batch {}'.format(i + 1), f'Observer step: {observer.step}')\n",
    "            # Check against the validation set\n",
    "            running_vloss = 0.0\n",
    "\n",
    "            # In evaluation mode some model specific operations can be omitted eg. dropout layer\n",
    "            net.train(False) # Switching to evaluation mode, eg. turning off regularisation\n",
    "            \n",
    "            for j, vdata in enumerate(validation_loader, 0):\n",
    "                vinputs, vlabels = vdata\n",
    "                if j % 1000 == 0:\n",
    "                    print('Validation Batch {}'.format(j + 1), f'Observer step: {observer.val_step}')\n",
    "                    voutputs = net(vinputs, topology=True)\n",
    "                else:\n",
    "                    voutputs = net(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss.item()\n",
    "            net.train(True) # Switching back to training mode, eg. turning on regularisation\n",
    "\n",
    "            avg_loss = running_loss / 1000\n",
    "            avg_vloss = running_vloss / len(validation_loader)\n",
    "\n",
    "            # Log the running loss averaged per batch\n",
    "            writer.add_scalars('Training vs. Validation Loss',\n",
    "                            { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                            epoch * len(training_loader) + i)\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "writer.flush()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T06:16:23.409506Z",
     "start_time": "2024-03-30T06:13:13.902494Z"
    }
   },
   "id": "b55605c01813edd3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while getting the repr of an object",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRecursionError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/IPython/core/formatters.py:708\u001B[0m, in \u001B[0;36mPlainTextFormatter.__call__\u001B[0;34m(self, obj)\u001B[0m\n\u001B[1;32m    701\u001B[0m stream \u001B[38;5;241m=\u001B[39m StringIO()\n\u001B[1;32m    702\u001B[0m printer \u001B[38;5;241m=\u001B[39m pretty\u001B[38;5;241m.\u001B[39mRepresentationPrinter(stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose,\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_width, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnewline,\n\u001B[1;32m    704\u001B[0m     max_seq_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_seq_length,\n\u001B[1;32m    705\u001B[0m     singleton_pprinters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msingleton_printers,\n\u001B[1;32m    706\u001B[0m     type_pprinters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtype_printers,\n\u001B[1;32m    707\u001B[0m     deferred_pprinters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeferred_printers)\n\u001B[0;32m--> 708\u001B[0m \u001B[43mprinter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpretty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    709\u001B[0m printer\u001B[38;5;241m.\u001B[39mflush()\n\u001B[1;32m    710\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m stream\u001B[38;5;241m.\u001B[39mgetvalue()\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/IPython/lib/pretty.py:410\u001B[0m, in \u001B[0;36mRepresentationPrinter.pretty\u001B[0;34m(self, obj)\u001B[0m\n\u001B[1;32m    407\u001B[0m                         \u001B[38;5;28;01mreturn\u001B[39;00m meth(obj, \u001B[38;5;28mself\u001B[39m, cycle)\n\u001B[1;32m    408\u001B[0m                 \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mobject\u001B[39m \\\n\u001B[1;32m    409\u001B[0m                         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__repr__\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n\u001B[0;32m--> 410\u001B[0m                     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_repr_pprint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcycle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    412\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _default_pprint(obj, \u001B[38;5;28mself\u001B[39m, cycle)\n\u001B[1;32m    413\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/IPython/lib/pretty.py:778\u001B[0m, in \u001B[0;36m_repr_pprint\u001B[0;34m(obj, p, cycle)\u001B[0m\n\u001B[1;32m    776\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001B[39;00m\n\u001B[1;32m    777\u001B[0m \u001B[38;5;66;03m# Find newlines and replace them with p.break_()\u001B[39;00m\n\u001B[0;32m--> 778\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mrepr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    779\u001B[0m lines \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39msplitlines()\n\u001B[1;32m    780\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m p\u001B[38;5;241m.\u001B[39mgroup():\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:2490\u001B[0m, in \u001B[0;36mModule.__repr__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2488\u001B[0m child_lines \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   2489\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modules\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m-> 2490\u001B[0m     mod_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mrepr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2491\u001B[0m     mod_str \u001B[38;5;241m=\u001B[39m _addindent(mod_str, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m   2492\u001B[0m     child_lines\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m key \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m mod_str)\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:2490\u001B[0m, in \u001B[0;36mModule.__repr__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2488\u001B[0m child_lines \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   2489\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modules\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m-> 2490\u001B[0m     mod_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mrepr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2491\u001B[0m     mod_str \u001B[38;5;241m=\u001B[39m _addindent(mod_str, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m   2492\u001B[0m     child_lines\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m key \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m mod_str)\n",
      "    \u001B[0;31m[... skipping similar frames: Module.__repr__ at line 2490 (984 times)]\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:2490\u001B[0m, in \u001B[0;36mModule.__repr__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2488\u001B[0m child_lines \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m   2489\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_modules\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m-> 2490\u001B[0m     mod_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mrepr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2491\u001B[0m     mod_str \u001B[38;5;241m=\u001B[39m _addindent(mod_str, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m   2492\u001B[0m     child_lines\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m key \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m mod_str)\n",
      "\u001B[0;31mRecursionError\u001B[0m: maximum recursion depth exceeded while getting the repr of an object"
     ]
    }
   ],
   "source": [
    "net.Filtration.parent"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T11:07:29.231235Z",
     "start_time": "2024-03-26T11:07:29.114732Z"
    }
   },
   "id": "67183400ee64f8c5"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [2.9638e-01, 2.9638e-01, 2.9638e-01, 2.9638e-01, 2.9638e-01,\n          2.9638e-01, 2.9638e-01, 1.9531e-03, 9.5074e-01, 1.8216e+00,\n          3.6419e+00, 3.8953e+00, 3.8743e+00, 3.9242e+00, 4.1424e+00,\n          4.3258e+00, 4.6051e+00, 5.0438e+00, 5.3503e+00, 5.9642e+00,\n          7.7310e+00, 5.8690e+00, 2.9638e-01, 2.9638e-01, 2.9638e-01,\n          2.9638e-01, 2.9638e-01, 2.9638e-01],\n         [1.1652e+00, 1.1652e+00, 1.1652e+00, 1.1652e+00, 1.1652e+00,\n          1.1652e+00, 1.1652e+00, 9.5074e-01, 0.0000e+00, 1.2722e+00,\n          3.3867e+00, 3.6372e+00, 3.5863e+00, 3.6075e+00, 3.8280e+00,\n          4.0399e+00, 4.3397e+00, 4.8145e+00, 5.1196e+00, 5.7134e+00,\n          7.4465e+00, 5.8486e+00, 1.1652e+00, 1.1652e+00, 1.1652e+00,\n          1.1652e+00, 1.1652e+00, 1.1652e+00],\n         [1.9318e+00, 1.9318e+00, 1.9318e+00, 1.9318e+00, 1.9318e+00,\n          1.9318e+00, 1.9318e+00, 1.8216e+00, 1.2722e+00, 2.7621e-03,\n          2.8458e+00, 3.1387e+00, 3.0817e+00, 3.1393e+00, 3.3884e+00,\n          3.6226e+00, 3.9130e+00, 4.4181e+00, 4.7701e+00, 5.2814e+00,\n          6.9829e+00, 5.8722e+00, 1.9318e+00, 1.9318e+00, 1.9318e+00,\n          1.9318e+00, 1.9318e+00, 1.9318e+00],\n         [3.7456e+00, 3.7456e+00, 3.7456e+00, 3.7456e+00, 3.7456e+00,\n          3.7456e+00, 3.7456e+00, 3.6419e+00, 3.3867e+00, 2.8458e+00,\n          0.0000e+00, 7.6910e-01, 1.1211e+00, 1.5074e+00, 1.9506e+00,\n          2.3097e+00, 2.6754e+00, 3.3741e+00, 3.8889e+00, 3.8913e+00,\n          5.5870e+00, 5.3225e+00, 3.7456e+00, 3.7456e+00, 3.7456e+00,\n          3.7456e+00, 3.7456e+00, 3.7456e+00],\n         [3.9942e+00, 3.9942e+00, 3.9942e+00, 3.9942e+00, 3.9942e+00,\n          3.9942e+00, 3.9942e+00, 3.8953e+00, 3.6372e+00, 3.1387e+00,\n          7.6910e-01, 0.0000e+00, 8.9895e-01, 1.4404e+00, 1.8671e+00,\n          2.2203e+00, 2.5556e+00, 3.2968e+00, 3.7992e+00, 3.7663e+00,\n          5.4112e+00, 5.3431e+00, 3.9942e+00, 3.9942e+00, 3.9942e+00,\n          3.9942e+00, 3.9942e+00, 3.9942e+00],\n         [3.9800e+00, 3.9800e+00, 3.9800e+00, 3.9800e+00, 3.9800e+00,\n          3.9800e+00, 3.9800e+00, 3.8743e+00, 3.5863e+00, 3.0817e+00,\n          1.1211e+00, 8.9895e-01, 0.0000e+00, 8.5569e-01, 1.6047e+00,\n          2.0116e+00, 2.3455e+00, 3.1156e+00, 3.6461e+00, 3.6357e+00,\n          5.2582e+00, 5.1532e+00, 3.9800e+00, 3.9800e+00, 3.9800e+00,\n          3.9800e+00, 3.9800e+00, 3.9800e+00],\n         [4.0337e+00, 4.0337e+00, 4.0337e+00, 4.0337e+00, 4.0337e+00,\n          4.0337e+00, 4.0337e+00, 3.9242e+00, 3.6075e+00, 3.1393e+00,\n          1.5074e+00, 1.4404e+00, 8.5569e-01, 0.0000e+00, 1.0788e+00,\n          1.7107e+00, 2.0978e+00, 2.8855e+00, 3.4456e+00, 3.4711e+00,\n          5.0487e+00, 4.8737e+00, 4.0337e+00, 4.0337e+00, 4.0337e+00,\n          4.0337e+00, 4.0337e+00, 4.0337e+00],\n         [4.2469e+00, 4.2469e+00, 4.2469e+00, 4.2469e+00, 4.2469e+00,\n          4.2469e+00, 4.2469e+00, 4.1424e+00, 3.8280e+00, 3.3884e+00,\n          1.9506e+00, 1.8671e+00, 1.6047e+00, 1.0788e+00, 0.0000e+00,\n          1.0767e+00, 1.6939e+00, 2.5150e+00, 3.0761e+00, 3.1788e+00,\n          4.7621e+00, 4.6113e+00, 4.2469e+00, 4.2469e+00, 4.2469e+00,\n          4.2469e+00, 4.2469e+00, 4.2469e+00],\n         [4.4195e+00, 4.4195e+00, 4.4195e+00, 4.4195e+00, 4.4195e+00,\n          4.4195e+00, 4.4195e+00, 4.3258e+00, 4.0399e+00, 3.6226e+00,\n          2.3097e+00, 2.2203e+00, 2.0116e+00, 1.7107e+00, 1.0767e+00,\n          0.0000e+00, 1.2292e+00, 2.2249e+00, 2.7314e+00, 2.9632e+00,\n          4.5939e+00, 4.3860e+00, 4.4195e+00, 4.4195e+00, 4.4195e+00,\n          4.4195e+00, 4.4195e+00, 4.4195e+00],\n         [4.6912e+00, 4.6912e+00, 4.6912e+00, 4.6912e+00, 4.6912e+00,\n          4.6912e+00, 4.6912e+00, 4.6051e+00, 4.3397e+00, 3.9130e+00,\n          2.6754e+00, 2.5556e+00, 2.3455e+00, 2.0978e+00, 1.6939e+00,\n          1.2292e+00, 1.9531e-03, 1.5888e+00, 2.2227e+00, 2.6258e+00,\n          4.2638e+00, 3.9159e+00, 4.6912e+00, 4.6912e+00, 4.6912e+00,\n          4.6912e+00, 4.6912e+00, 4.6912e+00],\n         [5.1273e+00, 5.1273e+00, 5.1273e+00, 5.1273e+00, 5.1273e+00,\n          5.1273e+00, 5.1273e+00, 5.0438e+00, 4.8145e+00, 4.4181e+00,\n          3.3741e+00, 3.2968e+00, 3.1156e+00, 2.8855e+00, 2.5150e+00,\n          2.2249e+00, 1.5888e+00, 0.0000e+00, 1.0783e+00, 1.9987e+00,\n          3.2904e+00, 3.0421e+00, 5.1273e+00, 5.1273e+00, 5.1273e+00,\n          5.1273e+00, 5.1273e+00, 5.1273e+00],\n         [5.4278e+00, 5.4278e+00, 5.4278e+00, 5.4278e+00, 5.4278e+00,\n          5.4278e+00, 5.4278e+00, 5.3503e+00, 5.1196e+00, 4.7701e+00,\n          3.8889e+00, 3.7992e+00, 3.6461e+00, 3.4456e+00, 3.0761e+00,\n          2.7314e+00, 2.2227e+00, 1.0783e+00, 9.7656e-04, 1.5341e+00,\n          2.7245e+00, 3.1127e+00, 5.4278e+00, 5.4278e+00, 5.4278e+00,\n          5.4278e+00, 5.4278e+00, 5.4278e+00],\n         [6.0498e+00, 6.0498e+00, 6.0498e+00, 6.0498e+00, 6.0498e+00,\n          6.0498e+00, 6.0498e+00, 5.9642e+00, 5.7134e+00, 5.2814e+00,\n          3.8913e+00, 3.7663e+00, 3.6357e+00, 3.4711e+00, 3.1788e+00,\n          2.9632e+00, 2.6258e+00, 1.9987e+00, 1.5341e+00, 0.0000e+00,\n          2.2251e+00, 3.9978e+00, 6.0498e+00, 6.0498e+00, 6.0498e+00,\n          6.0498e+00, 6.0498e+00, 6.0498e+00],\n         [7.8098e+00, 7.8098e+00, 7.8098e+00, 7.8098e+00, 7.8098e+00,\n          7.8098e+00, 7.8098e+00, 7.7310e+00, 7.4465e+00, 6.9829e+00,\n          5.5870e+00, 5.4112e+00, 5.2582e+00, 5.0487e+00, 4.7621e+00,\n          4.5939e+00, 4.2638e+00, 3.2904e+00, 2.7245e+00, 2.2251e+00,\n          1.3811e-03, 4.6943e+00, 7.8098e+00, 7.8098e+00, 7.8098e+00,\n          7.8098e+00, 7.8098e+00, 7.8098e+00],\n         [5.9371e+00, 5.9371e+00, 5.9371e+00, 5.9371e+00, 5.9371e+00,\n          5.9371e+00, 5.9371e+00, 5.8690e+00, 5.8486e+00, 5.8722e+00,\n          5.3225e+00, 5.3431e+00, 5.1532e+00, 4.8737e+00, 4.6113e+00,\n          4.3860e+00, 3.9159e+00, 3.0421e+00, 3.1127e+00, 3.9978e+00,\n          4.6943e+00, 1.3811e-03, 5.9371e+00, 5.9371e+00, 5.9371e+00,\n          5.9371e+00, 5.9371e+00, 5.9371e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 2.9638e-01, 1.1652e+00, 1.9318e+00,\n          3.7456e+00, 3.9942e+00, 3.9800e+00, 4.0337e+00, 4.2469e+00,\n          4.4195e+00, 4.6912e+00, 5.1273e+00, 5.4278e+00, 6.0498e+00,\n          7.8098e+00, 5.9371e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n          0.0000e+00, 0.0000e+00, 0.0000e+00]]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdata = next(iter(validation_loader))\n",
    "vinputs, vlabels = vdata\n",
    "d = image_distance(vinputs[0].unsqueeze(0)).unsqueeze(0)\n",
    "d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T07:41:53.982106Z",
     "start_time": "2024-03-22T07:41:49.870210Z"
    }
   },
   "id": "fe37d485c1056ab4"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "VR = VietorisRipsPersistence(metric='precomputed')\n",
    "Betti = BettiCurve()\n",
    "pi = VR.fit_transform(d)\n",
    "bc = Betti.fit_transform(pi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T07:30:34.197904Z",
     "start_time": "2024-03-22T07:30:34.190711Z"
    }
   },
   "id": "8ba9db54e6324037"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 9, 15, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14,\n         14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 12, 12, 11, 10,\n         10, 10, 10, 10,  7,  7,  7,  7,  7,  6,  5,  5,  5,  5,  5,  5,\n          5,  5,  4,  4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n          3,  3,  3,  3,  3,  3,  3,  3,  3,  2,  2,  2,  2,  2,  2,  2,\n          2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  1,  1,  1,\n          1,  1,  1,  0],\n        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0,  0,  0]]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T07:30:58.571212Z",
     "start_time": "2024-03-22T07:30:58.564414Z"
    }
   },
   "id": "e3c2ec75526af742"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdadapy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n\u001B[0;32m----> 3\u001B[0m dim \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mData\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdistances\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43md\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_id_2NN\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/dadapy/id_estimation.py:176\u001B[0m, in \u001B[0;36mIdEstimation.compute_id_2NN\u001B[0;34m(self, algorithm, mu_fraction, data_fraction, n_iter, set_attr)\u001B[0m\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_distances()\n\u001B[1;32m    175\u001B[0m mus \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistances[:, \u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistances[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m--> 176\u001B[0m intrinsic_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_id_2NN\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmu_fraction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malgorithm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    177\u001B[0m intrinsic_dim_err \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m    178\u001B[0m intrinsic_dim_scale \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistances[:, np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m])])\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/dadapy/id_estimation.py:93\u001B[0m, in \u001B[0;36mIdEstimation._compute_id_2NN\u001B[0;34m(self, mus, mu_fraction, algorithm)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfunc\u001B[39m(x, m):\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m m \u001B[38;5;241m*\u001B[39m x\n\u001B[0;32m---> 93\u001B[0m intrinsic_dim, _ \u001B[38;5;241m=\u001B[39m \u001B[43mcurve_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_mus_reduced\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;66;03m# curve_fit returns a 1-element array\u001B[39;00m\n\u001B[1;32m     95\u001B[0m intrinsic_dim \u001B[38;5;241m=\u001B[39m intrinsic_dim[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/scipy/optimize/_minpack_py.py:910\u001B[0m, in \u001B[0;36mcurve_fit\u001B[0;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, full_output, nan_policy, **kwargs)\u001B[0m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(xdata, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m, np\u001B[38;5;241m.\u001B[39mndarray)):\n\u001B[1;32m    907\u001B[0m     \u001B[38;5;66;03m# `xdata` is passed straight to the user-defined `f`, so allow\u001B[39;00m\n\u001B[1;32m    908\u001B[0m     \u001B[38;5;66;03m# non-array_like `xdata`.\u001B[39;00m\n\u001B[1;32m    909\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m check_finite:\n\u001B[0;32m--> 910\u001B[0m         xdata \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray_chkfinite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    911\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    912\u001B[0m         xdata \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(xdata, \u001B[38;5;28mfloat\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/numpy/lib/function_base.py:630\u001B[0m, in \u001B[0;36masarray_chkfinite\u001B[0;34m(a, dtype, order)\u001B[0m\n\u001B[1;32m    628\u001B[0m a \u001B[38;5;241m=\u001B[39m asarray(a, dtype\u001B[38;5;241m=\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder)\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m a\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mchar \u001B[38;5;129;01min\u001B[39;00m typecodes[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllFloat\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misfinite(a)\u001B[38;5;241m.\u001B[39mall():\n\u001B[0;32m--> 630\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray must not contain infs or NaNs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "\u001B[0;31mValueError\u001B[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "from dadapy import data\n",
    "\n",
    "dim = data.Data(distances=d[0].numpy()).compute_id_2NN()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T07:41:59.509605Z",
     "start_time": "2024-03-22T07:41:59.390329Z"
    }
   },
   "id": "c654daeef010be2"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [2.96e-01, 2.96e-01, 2.96e-01, 2.96e-01, 2.96e-01, 2.96e-01,\n        2.96e-01, 1.95e-03, 9.51e-01, 1.82e+00, 3.64e+00, 3.90e+00,\n        3.87e+00, 3.92e+00, 4.14e+00, 4.33e+00, 4.61e+00, 5.04e+00,\n        5.35e+00, 5.96e+00, 7.73e+00, 5.87e+00, 2.96e-01, 2.96e-01,\n        2.96e-01, 2.96e-01, 2.96e-01, 2.96e-01],\n       [1.17e+00, 1.17e+00, 1.17e+00, 1.17e+00, 1.17e+00, 1.17e+00,\n        1.17e+00, 9.51e-01, 0.00e+00, 1.27e+00, 3.39e+00, 3.64e+00,\n        3.59e+00, 3.61e+00, 3.83e+00, 4.04e+00, 4.34e+00, 4.81e+00,\n        5.12e+00, 5.71e+00, 7.45e+00, 5.85e+00, 1.17e+00, 1.17e+00,\n        1.17e+00, 1.17e+00, 1.17e+00, 1.17e+00],\n       [1.93e+00, 1.93e+00, 1.93e+00, 1.93e+00, 1.93e+00, 1.93e+00,\n        1.93e+00, 1.82e+00, 1.27e+00, 2.76e-03, 2.85e+00, 3.14e+00,\n        3.08e+00, 3.14e+00, 3.39e+00, 3.62e+00, 3.91e+00, 4.42e+00,\n        4.77e+00, 5.28e+00, 6.98e+00, 5.87e+00, 1.93e+00, 1.93e+00,\n        1.93e+00, 1.93e+00, 1.93e+00, 1.93e+00],\n       [3.75e+00, 3.75e+00, 3.75e+00, 3.75e+00, 3.75e+00, 3.75e+00,\n        3.75e+00, 3.64e+00, 3.39e+00, 2.85e+00, 0.00e+00, 7.69e-01,\n        1.12e+00, 1.51e+00, 1.95e+00, 2.31e+00, 2.68e+00, 3.37e+00,\n        3.89e+00, 3.89e+00, 5.59e+00, 5.32e+00, 3.75e+00, 3.75e+00,\n        3.75e+00, 3.75e+00, 3.75e+00, 3.75e+00],\n       [3.99e+00, 3.99e+00, 3.99e+00, 3.99e+00, 3.99e+00, 3.99e+00,\n        3.99e+00, 3.90e+00, 3.64e+00, 3.14e+00, 7.69e-01, 0.00e+00,\n        8.99e-01, 1.44e+00, 1.87e+00, 2.22e+00, 2.56e+00, 3.30e+00,\n        3.80e+00, 3.77e+00, 5.41e+00, 5.34e+00, 3.99e+00, 3.99e+00,\n        3.99e+00, 3.99e+00, 3.99e+00, 3.99e+00],\n       [3.98e+00, 3.98e+00, 3.98e+00, 3.98e+00, 3.98e+00, 3.98e+00,\n        3.98e+00, 3.87e+00, 3.59e+00, 3.08e+00, 1.12e+00, 8.99e-01,\n        0.00e+00, 8.56e-01, 1.60e+00, 2.01e+00, 2.35e+00, 3.12e+00,\n        3.65e+00, 3.64e+00, 5.26e+00, 5.15e+00, 3.98e+00, 3.98e+00,\n        3.98e+00, 3.98e+00, 3.98e+00, 3.98e+00],\n       [4.03e+00, 4.03e+00, 4.03e+00, 4.03e+00, 4.03e+00, 4.03e+00,\n        4.03e+00, 3.92e+00, 3.61e+00, 3.14e+00, 1.51e+00, 1.44e+00,\n        8.56e-01, 0.00e+00, 1.08e+00, 1.71e+00, 2.10e+00, 2.89e+00,\n        3.45e+00, 3.47e+00, 5.05e+00, 4.87e+00, 4.03e+00, 4.03e+00,\n        4.03e+00, 4.03e+00, 4.03e+00, 4.03e+00],\n       [4.25e+00, 4.25e+00, 4.25e+00, 4.25e+00, 4.25e+00, 4.25e+00,\n        4.25e+00, 4.14e+00, 3.83e+00, 3.39e+00, 1.95e+00, 1.87e+00,\n        1.60e+00, 1.08e+00, 0.00e+00, 1.08e+00, 1.69e+00, 2.52e+00,\n        3.08e+00, 3.18e+00, 4.76e+00, 4.61e+00, 4.25e+00, 4.25e+00,\n        4.25e+00, 4.25e+00, 4.25e+00, 4.25e+00],\n       [4.42e+00, 4.42e+00, 4.42e+00, 4.42e+00, 4.42e+00, 4.42e+00,\n        4.42e+00, 4.33e+00, 4.04e+00, 3.62e+00, 2.31e+00, 2.22e+00,\n        2.01e+00, 1.71e+00, 1.08e+00, 0.00e+00, 1.23e+00, 2.22e+00,\n        2.73e+00, 2.96e+00, 4.59e+00, 4.39e+00, 4.42e+00, 4.42e+00,\n        4.42e+00, 4.42e+00, 4.42e+00, 4.42e+00],\n       [4.69e+00, 4.69e+00, 4.69e+00, 4.69e+00, 4.69e+00, 4.69e+00,\n        4.69e+00, 4.61e+00, 4.34e+00, 3.91e+00, 2.68e+00, 2.56e+00,\n        2.35e+00, 2.10e+00, 1.69e+00, 1.23e+00, 1.95e-03, 1.59e+00,\n        2.22e+00, 2.63e+00, 4.26e+00, 3.92e+00, 4.69e+00, 4.69e+00,\n        4.69e+00, 4.69e+00, 4.69e+00, 4.69e+00],\n       [5.13e+00, 5.13e+00, 5.13e+00, 5.13e+00, 5.13e+00, 5.13e+00,\n        5.13e+00, 5.04e+00, 4.81e+00, 4.42e+00, 3.37e+00, 3.30e+00,\n        3.12e+00, 2.89e+00, 2.52e+00, 2.22e+00, 1.59e+00, 0.00e+00,\n        1.08e+00, 2.00e+00, 3.29e+00, 3.04e+00, 5.13e+00, 5.13e+00,\n        5.13e+00, 5.13e+00, 5.13e+00, 5.13e+00],\n       [5.43e+00, 5.43e+00, 5.43e+00, 5.43e+00, 5.43e+00, 5.43e+00,\n        5.43e+00, 5.35e+00, 5.12e+00, 4.77e+00, 3.89e+00, 3.80e+00,\n        3.65e+00, 3.45e+00, 3.08e+00, 2.73e+00, 2.22e+00, 1.08e+00,\n        9.77e-04, 1.53e+00, 2.72e+00, 3.11e+00, 5.43e+00, 5.43e+00,\n        5.43e+00, 5.43e+00, 5.43e+00, 5.43e+00],\n       [6.05e+00, 6.05e+00, 6.05e+00, 6.05e+00, 6.05e+00, 6.05e+00,\n        6.05e+00, 5.96e+00, 5.71e+00, 5.28e+00, 3.89e+00, 3.77e+00,\n        3.64e+00, 3.47e+00, 3.18e+00, 2.96e+00, 2.63e+00, 2.00e+00,\n        1.53e+00, 0.00e+00, 2.23e+00, 4.00e+00, 6.05e+00, 6.05e+00,\n        6.05e+00, 6.05e+00, 6.05e+00, 6.05e+00],\n       [7.81e+00, 7.81e+00, 7.81e+00, 7.81e+00, 7.81e+00, 7.81e+00,\n        7.81e+00, 7.73e+00, 7.45e+00, 6.98e+00, 5.59e+00, 5.41e+00,\n        5.26e+00, 5.05e+00, 4.76e+00, 4.59e+00, 4.26e+00, 3.29e+00,\n        2.72e+00, 2.23e+00, 1.38e-03, 4.69e+00, 7.81e+00, 7.81e+00,\n        7.81e+00, 7.81e+00, 7.81e+00, 7.81e+00],\n       [5.94e+00, 5.94e+00, 5.94e+00, 5.94e+00, 5.94e+00, 5.94e+00,\n        5.94e+00, 5.87e+00, 5.85e+00, 5.87e+00, 5.32e+00, 5.34e+00,\n        5.15e+00, 4.87e+00, 4.61e+00, 4.39e+00, 3.92e+00, 3.04e+00,\n        3.11e+00, 4.00e+00, 4.69e+00, 1.38e-03, 5.94e+00, 5.94e+00,\n        5.94e+00, 5.94e+00, 5.94e+00, 5.94e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00],\n       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 2.96e-01, 1.17e+00, 1.93e+00, 3.75e+00, 3.99e+00,\n        3.98e+00, 4.03e+00, 4.25e+00, 4.42e+00, 4.69e+00, 5.13e+00,\n        5.43e+00, 6.05e+00, 7.81e+00, 5.94e+00, 0.00e+00, 0.00e+00,\n        0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00]], dtype=float32)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqv = [list()] * d[0].shape[0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T07:42:22.129322Z",
     "start_time": "2024-03-22T07:42:22.110668Z"
    }
   },
   "id": "105e0d2e46cee303"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(list(d.isinf().flatten()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T07:41:32.115357Z",
     "start_time": "2024-03-22T07:41:32.106060Z"
    }
   },
   "id": "a90bbe06b595f5b1"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/dadapy/id_estimation.py:175: RuntimeWarning: invalid value encountered in divide\n",
      "  mus = self.distances[:, 2] / self.distances[:, 1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      4\u001B[0m z \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m3\u001B[39m))\n\u001B[0;32m----> 5\u001B[0m \u001B[43mData\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdistances\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mz\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_id_2NN\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/dadapy/id_estimation.py:176\u001B[0m, in \u001B[0;36mIdEstimation.compute_id_2NN\u001B[0;34m(self, algorithm, mu_fraction, data_fraction, n_iter, set_attr)\u001B[0m\n\u001B[1;32m    173\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_distances()\n\u001B[1;32m    175\u001B[0m mus \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistances[:, \u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistances[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m--> 176\u001B[0m intrinsic_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_id_2NN\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmu_fraction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malgorithm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    177\u001B[0m intrinsic_dim_err \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m    178\u001B[0m intrinsic_dim_scale \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistances[:, np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m])])\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/dadapy/id_estimation.py:93\u001B[0m, in \u001B[0;36mIdEstimation._compute_id_2NN\u001B[0;34m(self, mus, mu_fraction, algorithm)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfunc\u001B[39m(x, m):\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m m \u001B[38;5;241m*\u001B[39m x\n\u001B[0;32m---> 93\u001B[0m intrinsic_dim, _ \u001B[38;5;241m=\u001B[39m \u001B[43mcurve_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_mus_reduced\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;66;03m# curve_fit returns a 1-element array\u001B[39;00m\n\u001B[1;32m     95\u001B[0m intrinsic_dim \u001B[38;5;241m=\u001B[39m intrinsic_dim[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/scipy/optimize/_minpack_py.py:910\u001B[0m, in \u001B[0;36mcurve_fit\u001B[0;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, full_output, nan_policy, **kwargs)\u001B[0m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(xdata, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m, np\u001B[38;5;241m.\u001B[39mndarray)):\n\u001B[1;32m    907\u001B[0m     \u001B[38;5;66;03m# `xdata` is passed straight to the user-defined `f`, so allow\u001B[39;00m\n\u001B[1;32m    908\u001B[0m     \u001B[38;5;66;03m# non-array_like `xdata`.\u001B[39;00m\n\u001B[1;32m    909\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m check_finite:\n\u001B[0;32m--> 910\u001B[0m         xdata \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray_chkfinite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    911\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    912\u001B[0m         xdata \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(xdata, \u001B[38;5;28mfloat\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/tadProject/.venv/lib/python3.9/site-packages/numpy/lib/function_base.py:630\u001B[0m, in \u001B[0;36masarray_chkfinite\u001B[0;34m(a, dtype, order)\u001B[0m\n\u001B[1;32m    628\u001B[0m a \u001B[38;5;241m=\u001B[39m asarray(a, dtype\u001B[38;5;241m=\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder)\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m a\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mchar \u001B[38;5;129;01min\u001B[39;00m typecodes[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllFloat\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misfinite(a)\u001B[38;5;241m.\u001B[39mall():\n\u001B[0;32m--> 630\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray must not contain infs or NaNs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "\u001B[0;31mValueError\u001B[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "from dadapy.data import Data\n",
    "import torch\n",
    "\n",
    "z = torch.zeros((3, 3))\n",
    "Data(distances=z.numpy()).compute_id_2NN()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T15:05:15.073213Z",
     "start_time": "2024-03-22T15:05:10.116563Z"
    }
   },
   "id": "518b280eb83650bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fc92360315c40485"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
