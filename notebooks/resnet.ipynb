{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "\n",
    "\n",
    "def plot(imgs, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0])\n",
    "    _, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        for col_idx, img in enumerate(row):\n",
    "            boxes = None\n",
    "            masks = None\n",
    "            if isinstance(img, tuple):\n",
    "                img, target = img\n",
    "                if isinstance(target, dict):\n",
    "                    boxes = target.get(\"boxes\")\n",
    "                    masks = target.get(\"masks\")\n",
    "                elif isinstance(target, tv_tensors.BoundingBoxes):\n",
    "                    boxes = target\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected target type: {type(target)}\")\n",
    "            img = F.to_image(img)\n",
    "            if img.dtype.is_floating_point and img.min() < 0:\n",
    "                # Poor man's re-normalization for the colors to be OK-ish. This\n",
    "                # is useful for images coming out of Normalize()\n",
    "                img -= img.min()\n",
    "                img /= img.max()\n",
    "\n",
    "            img = F.to_dtype(img, torch.uint8, scale=True)\n",
    "            if boxes is not None:\n",
    "                img = draw_bounding_boxes(img, boxes, colors=\"yellow\", width=3)\n",
    "            if masks is not None:\n",
    "                img = draw_segmentation_masks(img, masks.to(torch.bool), colors=[\"green\"] * masks.shape[0], alpha=.65)\n",
    "\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(img.permute(1, 2, 0).numpy(), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T09:36:43.184943Z",
     "start_time": "2024-04-01T09:36:38.642156Z"
    }
   },
   "id": "7b0bfa09cc997e04",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision.transforms as v1\n",
    "from torchvision.io import read_image\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# If you're trying to run that on collab, you can download the assets and the\n",
    "# helpers from https://github.com/pytorch/vision/tree/main/gallery/\n",
    "import sys\n",
    "sys.path += [\"../transforms\"]\n",
    "ASSETS_PATH = Path('assets')"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-01T09:36:43.197738Z",
     "start_time": "2024-04-01T09:36:43.188302Z"
    }
   },
   "id": "initial_id",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dog1 = read_image(str(ASSETS_PATH / 'dog1.jpg'))\n",
    "dog2 = read_image(str(ASSETS_PATH / 'dog2.jpg'))\n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    v1.RandomCrop(224),\n",
    "    v1.RandomHorizontalFlip(p=0.3),\n",
    ")\n",
    "\n",
    "scripted_transforms = torch.jit.script(transforms)\n",
    "\n",
    "plot([dog1, scripted_transforms(dog1), dog2, scripted_transforms(dog2)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T09:36:43.984035Z",
     "start_time": "2024-04-01T09:36:43.199997Z"
    }
   },
   "id": "25ab31fff287bce0",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights, ResNet\n",
    "\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        weights = ResNet18_Weights.DEFAULT\n",
    "        self.resnet18 = resnet18(weights=weights, progress=False).eval()\n",
    "        self.transforms = weights.transforms(antialias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            x = self.transforms(x)\n",
    "            y_pred = self.resnet18(x)\n",
    "            return y_pred.argmax(dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T09:36:43.995711Z",
     "start_time": "2024-04-01T09:36:43.986796Z"
    }
   },
   "id": "a8114975e5922d9a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from nn import TopologyObserver\n",
    "from topology import Persistence, IntrinsicDimension\n",
    "\n",
    "predictor = Predictor()\n",
    "writer = SummaryWriter('runs/resnet_experiment_1')\n",
    "\n",
    "Filtration = Persistence()\n",
    "Dimension = IntrinsicDimension()\n",
    "\n",
    "net = predictor.resnet18\n",
    "observer = TopologyObserver(\n",
    "    net, writer=writer,\n",
    "    post_topology=[\n",
    "        (net.conv1, [\n",
    "            (Dimension, {'label': 'Dimension Analysis'})\n",
    "        ]),\n",
    "        (net.layer1, [\n",
    "            (Dimension, {'label': 'Dimension Analysis'})\n",
    "        ]),\n",
    "        (net.layer4, [\n",
    "            (Dimension, {'label': 'Dimension Analysis'})\n",
    "        ])\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T09:36:45.731627Z",
     "start_time": "2024-04-01T09:36:43.995994Z"
    }
   },
   "id": "d1df1704bb541f57",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "batch = torch.stack([dog1, dog2])\n",
    "\n",
    "res = predictor(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T09:37:20.071509Z",
     "start_time": "2024-04-01T09:36:45.734213Z"
    }
   },
   "id": "a02329bbcd7b3954",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "predictor.resnet18.conv1.register_forward_hook(lambda s, a, r: print(r.shape))\n",
    "predictor.resnet18.layer1.register_forward_hook(lambda s, a, r: print(r.shape))\n",
    "predictor.resnet18.layer2.register_forward_hook(lambda s, a, r: print(r.shape))\n",
    "predictor.resnet18.layer3.register_forward_hook(lambda s, a, r: print(r.shape))\n",
    "predictor.resnet18.layer4.register_forward_hook(lambda s, a, r: print(r.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T09:18:03.859492Z",
     "start_time": "2024-04-01T09:18:03.799998Z"
    }
   },
   "id": "169f1608e3875fab",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "predictor.resnet18.conv1.register_forward_hook(lambda s, a, r: print(r.shape[2] * r.shape[3]))\n",
    "predictor.resnet18.layer1.register_forward_hook(lambda s, a, r: print(r.shape[2] * r.shape[3]))\n",
    "predictor.resnet18.layer2.register_forward_hook(lambda s, a, r: print(r.shape[2] * r.shape[3]))\n",
    "predictor.resnet18.layer3.register_forward_hook(lambda s, a, r: print(r.shape[2] * r.shape[3]))\n",
    "predictor.resnet18.layer4.register_forward_hook(lambda s, a, r: print(r.shape[2] * r.shape[3]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T09:21:00.024458Z",
     "start_time": "2024-04-01T09:20:59.957547Z"
    }
   },
   "id": "14a61972cdf65322",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\n",
    "\n",
    "res = predictor(batch)\n",
    "res_scripted = scripted_predictor(batch)\n",
    "\n",
    "with open(Path('assets') / 'imagenet_class_index.json') as labels_file:\n",
    "    labels = json.load(labels_file)\n",
    "\n",
    "for i, (pred, pred_scripted) in enumerate(zip(res, res_scripted)):\n",
    "    assert pred == pred_scripted\n",
    "    print(f\"Prediction for Dog {i + 1}: {labels[str(pred.item())]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-01T09:22:59.922617Z"
    }
   },
   "id": "96ece4ad73dbef80",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "dog1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T09:45:30.762932Z",
     "start_time": "2024-03-31T09:45:30.694290Z"
    }
   },
   "id": "492841d7bbf86f4d",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1cf694e716108277",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "predictor(dog1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T09:50:27.204928Z",
     "start_time": "2024-03-31T09:50:26.514627Z"
    }
   },
   "id": "46ceb4f3c3a333b4",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/resnet_experiment_2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:04:34.259193Z",
     "start_time": "2024-03-31T14:04:34.209655Z"
    }
   },
   "id": "5cdd2c3b2ca5b7d1",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from nn import TopologyObserver\n",
    "from topology import Persistence, IntrinsicDimension\n",
    "\n",
    "Filtration = Persistence()\n",
    "Dimension = IntrinsicDimension()\n",
    "\n",
    "net = predictor.resnet18\n",
    "observer = TopologyObserver(\n",
    "    net, writer=writer, pre_topology=[\n",
    "        (net.conv1, [\n",
    "            (Filtration, {'label': 'Input', 'distances': False, 'batches': True}),\n",
    "            (Dimension, {'label': 'Dimension Analysis 2', 'distances': False, 'batches': True})\n",
    "        ])\n",
    "    ],\n",
    "    post_topology=[\n",
    "        (net.layer1, [\n",
    "            (Filtration, {'label': 'Hidden 1', 'distances': False, 'batches': True}),\n",
    "            (Dimension, {'label': 'Dimension Analysis', 'distances': False, 'batches': True})\n",
    "        ]),\n",
    "        (net.layer4, [\n",
    "            (Filtration, {'label': 'Hidden 4', 'distances': False, 'batches': True}),\n",
    "            (Dimension, {'label': 'Dimension Analysis', 'distances': False, 'batches': True})\n",
    "        ])\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:05:16.154439Z",
     "start_time": "2024-03-31T14:05:01.275582Z"
    }
   },
   "id": "6e535576044ea39a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictor(batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T14:05:23.195767Z"
    }
   },
   "id": "73d0c5148620098a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7764f05dd8e812",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
